{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bilby\n",
    "from sympy import sin,cos,log,sqrt\n",
    "from astropy import constants as const\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import six\n",
    "\n",
    "OrbitRadiusInS = 1e8 /const.c.value    # 1e5 km\n",
    "MearthInS      = const.M_earth.value*const.G.value/const.c.value**3\n",
    "OrbitPeriodInS = 2*np.pi*np.sqrt(OrbitRadiusInS**3/MearthInS)\n",
    "YearInS  = 31536000.0   # one year in [s]\n",
    "\n",
    "c = 299792458.0  # m/s\n",
    "G = 6.67*1.0e-11 \n",
    "AU = 1.5e+11\n",
    "parsec = 3.085677581491367e+16  # m\n",
    "solar_mass = 1.9885469549614615e+30  # Kg\n",
    "\n",
    "def InspiralWaveform(t, m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS):\n",
    "    c = 299792458.0  # m/s\n",
    "    G = 6.67*1.0e-11 \n",
    "    AU = 1.5e11\n",
    "    fm = 1.0/YearInS\n",
    "    eta = m1*m2/(m1+m2)**2  # symmetric mass ratio \n",
    "    m = m1+m2     # total mass\n",
    "    tau = c**3*eta/(5*G*m)*(Tc-t);\n",
    "    wt = c**3/(8*G*m)*(tau**(-3/8)+(743/2688+11/32*eta)*tau**(-5/8)-3*np.pi/10*tau**(-3/4)\\\n",
    "        +(1855099/14450688+56975/258048*eta+371/2048*eta**2)*tau**(-7/8))\n",
    "    PHI = -2/eta*(tau**(5/8)+(3715/8064+55/96*eta)*tau**(3/8)-3*np.pi/4*tau**(1/4)\\\n",
    "        +(9275495/14450688+284875/258048*eta+1855/2048*eta**2)*tau**(1/8))\\\n",
    "        +wt*AU/c*sin(thetaS)*cos(2*np.pi*fm*t-phiS)      # phi_Doppler\n",
    "    x = (G*m*wt/c**3)**(2/3)\n",
    "    hplus = 2*G*m*eta/(c**2*DL)*(1+cos(iota)**2)*x*cos(PHI+phic)\n",
    "    hcros = -4*G*m*eta/(c**2*DL)*cos(iota)*x*sin(PHI+phic)\n",
    "    return hplus, hcros\n",
    "\n",
    "def Dplus_TQ(t,thetaS,phiS):\n",
    "    \"\"\"For TianQin (one Michelson interferometer): (thetaS,phiS) is location of source,\n",
    "    (thJ,phJ) is latitude and longitude of J0806 in heliocentric-ecliptic frame\"\"\"\n",
    "    thJ  = 1.65273\n",
    "    phJ  = 2.10213\n",
    "    kap = 2*np.pi/OrbitPeriodInS* t\n",
    "#    kap = 2*np.pi/YearInS* t(f,theta)\n",
    "    return np.sqrt(3.)/32*(8*cos(2*kap) *((3 + cos(2*thetaS)) *sin(2*(phiS - phJ))*  \n",
    "            cos(thJ) + 2*sin(thJ) *sin(phiS - phJ)*sin(2*thetaS))- 2*sin(2*kap)* (3 +               \n",
    "            cos(2*(phiS - phJ))*(9 + cos(2*thetaS)*(3 + cos(2*thJ))) -6 *cos(2*thJ)*(sin(phiS - phJ))**2 -               \n",
    "            6* cos(2*thetaS)*(sin(thJ))**2 + 4*cos(phiS - phJ)*sin(2*thJ)*sin(2*thetaS))) \n",
    "\n",
    "def Dcros_TQ(t,thetaS,phiS):\n",
    "    \"\"\"For TianQin (one Michelson interferometer): (thetaS,phiS) is location of source, \n",
    "    (thJ,phJ) is latitude and longitude of J0806 in heliocentric-ecliptic frame\"\"\"\n",
    "    thJ  = 1.65273\n",
    "    phJ  = 2.10213\n",
    "    kap = 2*np.pi/OrbitPeriodInS* t\n",
    "#    kap = 2*np.pi/YearInS* t(f,theta)\n",
    "    return np.sqrt(3.)/4*(-4*cos(2*kap)*(cos(2*(phiS-phJ))*cos(thJ)*cos(thetaS)+                 \n",
    "            cos(phiS-phJ)*sin(thetaS)*sin(thJ))+sin(2*kap)*(cos(thetaS)*(3+cos(2*thJ))*sin(2*(phJ-phiS))+                \n",
    "            2*sin(phJ-phiS)*sin(thetaS)*sin(2*thJ)))\n",
    "\n",
    "def Fplus_TQ(t,thetaS,phiS,psi):\n",
    "    \"\"\"antenna pattern function for '+' mode\"\"\"\n",
    "    return (cos(2*psi)*Dplus_TQ(t,thetaS,phiS)-sin(2*psi)*Dcros_TQ(t,thetaS,phiS))/2.\n",
    "\n",
    "def Fcros_TQ(t,thetaS,phiS,psi):\n",
    "    \"\"\"antenna pattern function for 'Ã—' mode\"\"\"\n",
    "    return (sin(2*psi)*Dplus_TQ(t,thetaS,phiS)+cos(2*psi)*Dcros_TQ(t,thetaS,phiS))/2.\n",
    "\n",
    "def model_mbhb(t,m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS):\n",
    "    Fplus = []\n",
    "    Fcros = []\n",
    "    hplus = []\n",
    "    hcros = []\n",
    "    \n",
    "    for i in t:\n",
    "        Fp = Fplus_TQ(i,thetaS,phiS,psi)\n",
    "        Fc = Fcros_TQ(i,thetaS,phiS,psi)\n",
    "        Fplus.append(Fp)\n",
    "        Fcros.append(Fc)\n",
    "        \n",
    "        hp, hc = InspiralWaveform(i,m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS)\n",
    "        hplus.append(hp)\n",
    "        hcros.append(hc)\n",
    "        \n",
    "    return np.array(Fplus)*np.array(hplus) + np.array(Fcros)*np.array(hcros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.53522173880766e-21 9.78153538646996e-21 1.02494655505059e-20\n",
      " -2.95449180303497e-21 -1.46274530390114e-20\n",
      " -6.06121778156835e-21 1.03313628128882e-20 1.05724192816875e-20\n",
      " -5.54390873343684e-21 -6.51402111108043e-21\n",
      " 7.88441559752760e-21 6.26793703655517e-21 -1.09714108711926e-20\n",
      " -6.48165712074815e-21 1.27488476297869e-20 2.78747020027553e-21\n",
      " -1.40121057962521e-20 1.79543875937988e-21 1.05989764531507e-20]\n"
     ]
    }
   ],
   "source": [
    "m1 = 1.0e6*solar_mass\n",
    "m2 = 2.0e5*solar_mass\n",
    "Tc = 1.04*YearInS\n",
    "DL = 11.01*1.0e9*parsec\n",
    "\n",
    "\n",
    "thetaS = 1.6398\n",
    "phiS = 4.1226\n",
    "psi = 1.373\n",
    "iota = 0.7647\n",
    "phic = 0.9849\n",
    "\n",
    "sigma = 1.0e-21\n",
    "\n",
    "duration = 1638400\n",
    "time = np.arange(0, duration, 86400)\n",
    "\n",
    "data = model_mbhb(time,m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS) + sigma*np.random.randn(len(time))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpnest.model import Model\n",
    "\n",
    "# set the model, likelihood and prior\n",
    "class MBHBModel(Model):\n",
    "    \"\"\"\n",
    "    A simple straight line model, with a Gaussian likelihood.\n",
    "    \n",
    "    Args:\n",
    "        data (:class:`numpy.ndarray`): an array containing the observed data\n",
    "        abscissa (:class:`numpy.ndarray`): an array containing the points at which the data were taken\n",
    "        modelfunc (function): a function defining the model\n",
    "        sigma (float): the standard deviation of the noise in the data\n",
    "        \n",
    "    \"\"\"\n",
    "    names = ['m1', 'm2', 'DL', 'Tc', 'iota', 'phic', 'psi', 'thetaS', 'phiS'] # parameter names (this is a required variables for the class)\n",
    "\n",
    "    m1min = 0.8e6*solar_mass  # lower range on c (the same as the uniform c prior lower bound)\n",
    "    m1max = 1.5e6*solar_mass   # upper range on c (the same as the uniform c prior upper bound)\n",
    "\n",
    "    m2min = 1.0e5*solar_mass     \n",
    "    m2max = 3.0e5*solar_mass \n",
    "    \n",
    "    DLmin = 9.0e9*parsec\n",
    "    DLmax = 12.0e9*parsec\n",
    "    \n",
    "    Tcmin = 0.9*YearInS\n",
    "    Tcmax = 1.2*YearInS\n",
    "    \n",
    "    iotamin = 0.0\n",
    "    iotamax = np.pi\n",
    "    \n",
    "    phicmin = 0.0\n",
    "    phicmax = 2*np.pi\n",
    "    \n",
    "    psimin = 0.0\n",
    "    psimax = np.pi\n",
    "    \n",
    "    thetaSmin = 0.0\n",
    "    thetaSmax = np.pi\n",
    "    \n",
    "    phiSmin = 0.0\n",
    "    phiSmax = 2*np.pi\n",
    "    \n",
    "    \n",
    "    m1bounds = [m1min, m1max]\n",
    "    m2bounds = [m2min, m2max]\n",
    "    DLbounds = [DLmin, DLmax]\n",
    "    Tcbounds = [Tcmin, Tcmax]\n",
    "    iotabounds = [iotamin, iotamax]\n",
    "    phicbounds = [phicmin, phicmax]\n",
    "    psibounds = [psimin, psimax]\n",
    "    thetaSbounds = [thetaSmin, thetaSmax]\n",
    "    phiSbounds = [phiSmin, phiSmax]\n",
    "\n",
    "    # NOTE: the bounds could instead be set through arguments passed to the __init__\n",
    "    # function for the class if wanted\n",
    "    bounds=[m1bounds, m2bounds, DLbounds, Tcbounds, iotabounds, phicbounds, psibounds, thetaSbounds, phiSbounds] # upper and lower bounds on each parameter (required for the class)\n",
    "\n",
    "    def __init__(self, data, time, modelfunc, sigma):\n",
    "        # set the data\n",
    "        self._data = data         # oberserved data\n",
    "#         self._abscissa = abscissa # points at which the observed data are taken\n",
    "        self._sigma = sigma       # standard deviation(s) of the data\n",
    "        self._logsigma = np.log(sigma) # log sigma here to save computations in the likelihood\n",
    "        self._ndata = len(data)   # number of data points\n",
    "        self._model = modelfunc   # model function\n",
    "\n",
    "    def log_likelihood(self, params):\n",
    "        \"\"\"\n",
    "        The natural logarithm of the likelihood function.\n",
    "\n",
    "        Args:\n",
    "            params (dict): a dictionary keyed to the parameter names.\n",
    "\n",
    "        Returns:\n",
    "            float: the log likelihood value.\n",
    "        \"\"\"\n",
    "        # extract the parameters\n",
    "        m1 = params['m1']\n",
    "        m2 = params['m2']\n",
    "        DL = params['DL']\n",
    "        Tc = params['Tc']\n",
    "        iota = params['iota']\n",
    "        phic = params['phic']\n",
    "        psi = params['psi']\n",
    "        thetaS = params['thetaS']\n",
    "        phiS = params['phiS']\n",
    "\n",
    "        # calculate the model\n",
    "        model = self._model(time, m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS)\n",
    "\n",
    "#         # normalisation\n",
    "#         norm = -0.5*self._ndata*LN2PI - self._ndata*self._logsigma\n",
    "\n",
    "#         # chi-squared\n",
    "#         chisq = np.sum(((self._data - model)/(self._sigma))**2)\n",
    "\n",
    "        return -np.vdot(self._data - model,self._data - model)\n",
    "\n",
    "#     def log_prior(self,p):\n",
    "#         \"\"\"\n",
    "#         The natural logarithm of the prior function.\n",
    "\n",
    "#         Args:\n",
    "#             p (dict): a dictionary keyed to parameter names.\n",
    "\n",
    "#         Returns:\n",
    "#             float: The log prior value.\n",
    "#         \"\"\"\n",
    "#         # the uniform priors are dealt with by just checking that we're within the bounds\n",
    "#         if not self.in_bounds(p): return -np.inf # check parameters are all in bounds\n",
    "\n",
    "# #         # Gaussian prior on m\n",
    "# #         lp = 0.\n",
    "# #         m = p['m']\n",
    "# #         lp -= 0.5*((m-self.mmu)/self.msigma)**2 # no need for normalisation constant on the prior\n",
    "\n",
    "#         return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPNest version: 0.9.7\n",
      "Running with 2 parallel threads\n"
     ]
    }
   ],
   "source": [
    "# import cpnest\n",
    "import cpnest\n",
    "\n",
    "print('CPNest version: {}'.format(cpnest.__version__))\n",
    "\n",
    "nlive = 1024      # number of live point\n",
    "maxmcmc = 1024    # maximum MCMC chain length\n",
    "nthreads = 2      # use one CPU core\n",
    "\n",
    "# set up the algorithm\n",
    "work = cpnest.CPNest(MBHBModel(data, time, model_mbhb, sigma), verbose=0,\n",
    "                     nthreads=nthreads, nlive=nlive, maxmcmc=maxmcmc);\n",
    "# run the algorithm\n",
    "from datetime import datetime\n",
    "t0 = datetime.now()\n",
    "work.run();\n",
    "t1 = datetime.now()\n",
    "\n",
    "timecpnest = (t1-t0)\n",
    "print(\"Time taken to run 'CPNest' is {} seconds\".format(timecpnest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logZcpnest = work.NS.logZ                     # value of log Z\n",
    "infogaincpnest = work.NS.state.info           # value of the information gain\n",
    "logZerrcpnest = np.sqrt(infogaincpnest/nlive) # estimate of the statistcal uncertainty on logZ\n",
    "\n",
    "# get the null log likelihood (evidence that the data is Gaussian noise with zero mean, and given standard devaition)\n",
    "# logZnull = work.user.log_likelihood({'m1': 0., 'm2': 0., 'DL':0., 'Tc':0., 'iota':0., 'phic':0., 'psi':0., 'thetaS':0., 'phiS':0.})\n",
    "\n",
    "print(six.u('log(Z) = {} \\u00B1 {}'.format(logZcpnest, logZerrcpnest)))\n",
    "\n",
    "# output the log Bayes factor\n",
    "# print('log Bayes factor is {}'.format(logZcpnest - logZnull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1chain_cpnest = work.posterior_samples['m1'] # extract chain of m1 values\n",
    "m2chain_cpnest = work.posterior_samples['m2'] # extract chain if m2 values\n",
    "DLchain_cpnest = work.posterior_samples['DL']\n",
    "Tcchain_cpnest = work.posterior_samples['Tc']\n",
    "iotachain_cpnest = work.posterior_samples['iota']\n",
    "phicchain_cpnest = work.posterior_samples['phic']\n",
    "psichain_cpnest = work.posterior_samples['psi']\n",
    "thetaSchain_cpnest = work.posterior_samples['thetaS']\n",
    "phiSchain_cpnest = work.posterior_samples['phiS']\n",
    "\n",
    "samples_cpnest = np.vstack((m1chain_cpnest/solar_mass, m2chain_cpnest/solar_mass, DLchain_cpnest/(1.0e9*parsec),\\\n",
    "                            Tcchain_cpnest/YearInS,iotachain_cpnest, \\\n",
    "                            phicchain_cpnest, psichain_cpnest, thetaSchain_cpnest, phiSchain_cpnest)).T\n",
    "\n",
    "# print out the number of posterior samples\n",
    "print('Number of posterior samples is {}'.format(samples_cpnest.shape[0]))\n",
    "\n",
    "# resdict['m1cpnest_mu'] = np.mean(samples_cpnest[:,0])      # mean of m samples\n",
    "# resdict['m1cpnest_sig'] = np.std(samples_cpnest[:,0])      # standard deviation of m samples\n",
    "# resdict['m2cpnest_mu'] = np.mean(samples_cpnest[:,1])      # mean of c samples\n",
    "# resdict['m2cpnest_sig'] = np.std(samples_cpnest[:,1])      # standard deviation of c samples\n",
    "# resdict['cccpnest'] = np.corrcoef(samples_cpnest.T)[0,1]  # correlation coefficient between parameters\n",
    "# resdict['cpnest_npos'] = len(samples_cpnest)              # number of posterior samples\n",
    "# resdict['cpnest_time'] = timecpnest                       # run time\n",
    "# resdict['cpnest_logZ'] = logZcpnest                       # log marginalised likelihood\n",
    "# resdict['cpnest_logZerr'] = logZerrcpnest                 # uncertainty on log(Z)\n",
    "\n",
    "# plot using corner.py\n",
    "import corner\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "true_value = [1.0e6*solar_mass, 2.0e5*solar_mass,11.01*1.0e9*parsec, 1.04*YearInS,0.7647,\\\n",
    "             0.9849,1.373,1.6398,4.1226]\n",
    "fig = corner.corner(samples_cpnest, labels=[r\"$m_1$\", r\"$m_2$\", r\"$DL$\",r\"$T_c$\",\\\n",
    "                                            r\"$\\iota$\",r\"$phi_c$\",r\"$\\psi$\",r\"$\\theta_S$\",r\"$\\phi_S$\"],\n",
    "                    quantiles=[0.25, 0.5, 0.75], truths= true_value,\n",
    "                   show_titles=True, title_kwargs={\"fontsize\": 16,}, fontweight='bold')\n",
    "fig.savefig('corner_mbhb.png', dpi =300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking signal in frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def create_frequency_series(sampling_frequency, duration):\n",
    "# #     number_of_samples = int(np.round(duration * sampling_frequency))\n",
    "# #     number_of_frequencies = int(np.round(number_of_samples / 2) + 1)\n",
    "\n",
    "# #     return np.linspace(start=0,\n",
    "# #                        stop=sampling_frequency / 2,\n",
    "# #                        num=number_of_frequencies)\n",
    "\n",
    "# # sampling_frequency = 1/50.0 \n",
    "# # data_fd = np.fft.fft(data_time)    # data in frequency\n",
    "# # data_fd = data_fd[0:int((len(data_fd))/2+1)]\n",
    "# # ff = create_frequency_series(2.0e-2, 1638400)\n",
    "\n",
    "# # hplus_fre = np.fft.fft(hplus)\n",
    "# # hplus_fre = hplus_fre[0:int((len(hplus_fre))/2+1)]\n",
    "# # hcros_fre = np.fft.fft(hcros)\n",
    "# # hcros_fre = hplus_fre[0:int((len(hcros_fre))/2+1)]\n",
    "\n",
    "# # data_power_spectral_density = data_fd*np.transpose(np.conjugate(data_fd)/duration)\n",
    "\n",
    "# def log_likelihood(duration, data_time, theta, t):\n",
    "#     \"\"\"\n",
    "#     Returns\n",
    "#     ------\n",
    "#     float: The real part of the log-likelihood for this interferometer\n",
    "#     \"\"\"\n",
    "# #     noise_power_spectral_density = 2*sigma**2*50\n",
    "#     hplus, hcros = np.array(InspiralWaveform(t,theta))\n",
    "#     ht = np.array(Fplus_TQ(t,theta))*np.array(hplus) + np.array(Fcros_TQ(t,theta))*np.array(hcros)\n",
    "# #     hf = np.fft.fft(hf)\n",
    "# #     hf = hf[0:int((len(hf))/2+1)]\n",
    "    \n",
    "#     log_l = - 2. / duration * np.vdot(data_time - ht,(data_time - ht))\n",
    "#     return log_l.real\n",
    "\n",
    "# def log_likelihood(duration, data_time, theta, t):\n",
    "#     \"\"\"\n",
    "#     Returns\n",
    "#     ------\n",
    "#     float: The real part of the log-likelihood for this interferometer\n",
    "#     \"\"\"\n",
    "# #     noise_power_spectral_density = 2*sigma**2*50\n",
    "#     hplus, hcros = np.array(InspiralWaveform(t,theta))\n",
    "#     ht = np.array(Fplus_TQ(t,theta))*np.array(hplus) + np.array(Fcros_TQ(t,theta))*np.array(hcros)\n",
    "# #     hf = np.fft.fft(hf)\n",
    "# #     hf = hf[0:int((len(hf))/2+1)]\n",
    "    \n",
    "#     log_l = - 2. / duration * np.vdot(data_time - ht,(data_time - ht))\n",
    "#     return log_l.real\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(9,6))\n",
    "# ax.plot(ff, np.sqrt(abs(data_power_spectral_density)))\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# ax.set_xlim([5.0e-6, 5.0e-4])\n",
    "# plt.xlabel('frequency (Hz)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.title('fd data')\n",
    "\n",
    "# # noise_power_spectrum_density = 2*sigma**2*50  #approximate\n",
    "# noise_power_spectral_density = np.fft.fft(noise)*np.transpose(np.conjugate(np.fft.fft(noise)))/duration\n",
    "# noise_power_spectral_density = noise_power_spectral_density[0:int((len(noise_power_spectral_density))/2+1)]\n",
    "# hf = hplus_fre + hcros_fre\n",
    "# snr = np.sqrt(np.real(np.trapz(abs(hf)**2/noise_power_spectral_density, ff)))\n",
    "\n",
    "# print(snr)\n",
    "\n",
    "# def noise_weighted_inner_product(aa, bb, power_spectral_density, duration):\n",
    "#     \"\"\"\n",
    "#     Calculate the noise weighted inner product between two arrays.\n",
    "    \n",
    "#     Returns\n",
    "#     ------\n",
    "#     Noise-weighted inner product.\n",
    "#     \"\"\"\n",
    "\n",
    "#     integrand = np.conj(aa) * bb / power_spectral_density\n",
    "#     return 4 / duration * np.sum(integrand)\n",
    "\n",
    "# def log_likelihood(duration, data_fd, hf, noise_power_spectral_density):\n",
    "#     \"\"\"\n",
    "#     Returns\n",
    "#     ------\n",
    "#     float: The real part of the log-likelihood for this interferometer\n",
    "#     \"\"\"\n",
    "    \n",
    "#     log_l = - 2. / duration * np.vdot(data_fd - hf,(data_fd - hf) /noise_power_spectral_density)\n",
    "#     return log_l.real\n",
    "\n",
    "# Loglikelihood = log_likelihood(duration, data_fd, hf, noise_power_spectral_density)\n",
    "# print(Loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cpnest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_likelihood(duration, data_time, theta, t):\n",
    "#     \"\"\"\n",
    "#     Returns\n",
    "#     ------\n",
    "#     float: The real part of the log-likelihood for this interferometer\n",
    "#     \"\"\"\n",
    "# #     noise_power_spectral_density = 2*sigma**2*50\n",
    "#     hplus, hcros = np.array(InspiralWaveform(t,theta))\n",
    "#     ht = np.array(Fplus_TQ(t,theta))*np.array(hplus) + np.array(Fcros_TQ(t,theta))*np.array(hcros)\n",
    "# #     hf = np.fft.fft(hf)\n",
    "# #     hf = hf[0:int((len(hf))/2+1)]\n",
    "    \n",
    "#     log_l = - 2. / duration * np.vdot(data_time - ht,(data_time - ht))\n",
    "#     return log_l.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def logposterior(duration, data_time, theta, t):\n",
    "#     \"\"\"\n",
    "#     The natural logarithm of the joint posterior.\n",
    "\n",
    "#     Args:\n",
    "#         theta (tuple): a sample containing individual parameter values\n",
    "#         data (list): the set of data/observations\n",
    "#         sigma (float): the standard deviation of the data points\n",
    "#         x (list): the abscissa values at which the data/model is defined\n",
    "#     \"\"\"\n",
    "\n",
    "#     lp = logprior(theta) # get the prior\n",
    "\n",
    "#     # if the prior is not finite return a probability of zero (log probability of -inf)\n",
    "#     if not np.isfinite(lp):\n",
    "#         return -np.inf\n",
    "\n",
    "#     # return the likeihood times the prior (log likelihood plus the log prior)\n",
    "#     return lp + log_likelihood(duration, data_time, theta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    ------\n",
    "    float: The real part of the log-likelihood for this interferometer\n",
    "    \"\"\"\n",
    "    \n",
    "    m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS = theta\n",
    "    hplus = []\n",
    "    hcros = []\n",
    "    for i in time:\n",
    "        hplus_temp, hcros_temp = np.array(InspiralWaveform(i,m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS))\n",
    "        hplus.append(hplus_temp)\n",
    "        hcros.append(hcros_temp)\n",
    "    \n",
    "    ht = np.array(Fplus_TQ(i,thetaS,phiS,psi))*np.array(hplus) + np.array(Fcros_TQ(i,thetaS,phiS,psi))*np.array(hcros)\n",
    "    \n",
    "    log_l = np.real(- 2. / duration * np.vdot(data_time - ht,(data_time - ht)))\n",
    "    return log_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_transform(theta):\n",
    "\n",
    "    # unpack the model parameters from the tuple\n",
    "#     m1,m2,DL,Tc,iota,phic,psi,thetaS,phiS=theta\n",
    "    m1prime, m2prime, DLprime, Tcprime, iotaprime, phicprime, psiprime, thetaSprime, phiSprime = theta\n",
    "    \n",
    "    # uniform prior on c\n",
    "    m1min = 5.0e5*solar_mass   # lower range of prior\n",
    "    m1max = 5.0e6*solar_mass   # upper range of prior\n",
    "    \n",
    "    m2min = 1.0e5*solar_mass   # lower range of prior\n",
    "    m2max = 5.0e5*solar_mass   # upper range of prior\n",
    "     \n",
    "    DLmin = 10*1.0e9*parsec\n",
    "    DLmax = 15*1.0e9*parsec\n",
    "    \n",
    "    Tcmin = 0.9*YearInS\n",
    "    Tcmax = 1.2*YearInS\n",
    "    \n",
    "    iotamin = 0\n",
    "    iotamax = np.pi\n",
    "    \n",
    "    phicmin = 0\n",
    "    phicmax = 2*np.pi\n",
    "     \n",
    "    psimin = 0\n",
    "    psimax = 2*np.pi\n",
    "    \n",
    "    thetaSmin = 0\n",
    "    thetaSmax = np.pi\n",
    "    \n",
    "    phiSmin = 0\n",
    "    phiSmax = 2*np.pi\n",
    "    \n",
    "    m1 = m1prime*(m1max-m1min)+m1min\n",
    "    m2 = m2prime*(m2max-m2min)+m2min\n",
    "    DL = DLprime*(DLmax-DLmin)+DLmin\n",
    "    Tc = Tcprime*(Tcmax-Tcmin)+Tcmin\n",
    "    iota = iotaprime*(iotamax - iotamin)+iotamin\n",
    "    phic = phicprime*(phicmax-phicmin)+phicmin\n",
    "    psi = psiprime*(psimax-psimin)+psimin\n",
    "    thetaS = thetaSprime*(thetaSmax - thetaSmin)+thetaSmin\n",
    "    phiS = phiSprime*(phiSmax-phiSmin)+phiSmin\n",
    "\n",
    "    return m1, m2, DL, Tc, iota, phic, psi, thetaS, phiS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nestle\n",
    "import nestle\n",
    "from datetime import datetime\n",
    "print('Nestle version: {}'.format(nestle.__version__))\n",
    "\n",
    "nlive = 1024     # number of live points\n",
    "method = 'multi' # use MutliNest algorithm\n",
    "ndims = 9        # two parameters\n",
    "tol = 0.1        # the stopping criterion\n",
    "\n",
    "t0 = datetime.now()\n",
    "res = nestle.sample(log_likelihood, prior_transform, ndims, method=method, npoints=nlive, dlogz=tol)\n",
    "t1 = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeultranest = (t1-t0)\n",
    "print(\"Time taken to run 'UltraNest' is {} seconds\".format(timeultranest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logZultranest = result['logZ']        # value of logZ\n",
    "logZerrultranest = result['logZerr']  # estimate of the statistcal uncertainty on logZ\n",
    "\n",
    "# output marginal likelihood\n",
    "print(six.u('Marginalised evidence is {} \\u00B1 {}'.format(logZultranest, logZerrultranest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = np.array([xi for ui, xi, Li, logwidth in result['weights']])\n",
    "probs = np.array([Li + logwidth for ui, xi, Li, logwidth in result['weights']])\n",
    "probs = np.exp(probs - probs.max())\n",
    "\n",
    "keepidx = np.where(np.random.rand(len(probs)) < probs)[0]\n",
    "\n",
    "samples_ultranest = nsamples[keepidx,:]\n",
    "\n",
    "resdict['multranest_mu'] = np.mean(samples_ultranest[:,0])      # mean of m samples\n",
    "resdict['multranest_sig'] = np.std(samples_ultranest[:,0])      # standard deviation of m samples\n",
    "resdict['cultranest_mu'] = np.mean(samples_ultranest[:,1])      # mean of c samples\n",
    "resdict['cultranest_sig'] = np.std(samples_ultranest[:,1])      # standard deviation of c samples\n",
    "resdict['ccultranest'] = np.corrcoef(samples_ultranest.T)[0,1]  # correlation coefficient between parameters\n",
    "resdict['ultranest_npos'] = len(samples_ultranest)              # number of posterior samples\n",
    "resdict['ultranest_time'] = timeultranest                       # run time\n",
    "resdict['ultranest_logZ'] = logZultranest                       # log marginalised likelihood\n",
    "resdict['ultranest_logZerr'] = logZerrultranest                 # uncertainty on log(Z)\n",
    "\n",
    "# plot using corner.py\n",
    "plotposts(samples_ultranest)\n",
    "\n",
    "print('Number of posterior samples is {}'.format(samples_ultranest.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
